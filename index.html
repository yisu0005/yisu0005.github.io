<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link href="https://fonts.googleapis.com/css2?family=Lato&display=swap" rel="stylesheet">
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<div id="layout-content">
<p><table class="imgtable"><tr><td>
<img src="img/yi.jpg" alt="Yi's photo" height="240" width="200" />&nbsp;</td>
<td align="left">
<p> <font size="+3">Yi Su </font> 
<img src="img/yi2.jpg" height="66" width="66" />
<br /><br /> Research Scientist
<br /><br /> Google Brain
<br /><br /> Email: <a href="mailto:yisumtv@google.com">yisumtv@google.com</a> 
</td></tr></table></p>
<h2>About Me</h2>
<p>I am a research scientist at Google Research, Brain Team. Previously, I was a PostDoctoral Researcher at EECS, UC Berkeley, working with Professor <a href="http://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>. I obtained my PhD in Statistics from Cornell University, advised by Professor <a href="http://www.cs.cornell.edu/people/tj/">Thorsten Joachims</a>. Prior to that, I received my BSc (Honors) in Mathematics from Nanyang Technological University in the beautiful Singapore. 
<p>I am interested in machine learning methods, algorithms, and systems. Speciﬁcally I am interested in learning from user behavioral data and implicit feedback in search engines, recommender systems and multi-sided market platforms. My current interest lies in off-policy evaluation and learning in contextual bandits and reinforcement learning.</p>

<h2>Preprints and Publications</h2>
<ul>
<li><p><b>Optimizing Rankings for Recommendation in Matching Markets</b>
<br /> Yi Su, Magd Bayoumi, Thorsten Joachims
<br /> <a href="https://arxiv.org/pdf/2106.01941.pdf">[PDF]</a>  World Wide Web Conference (WWW), 2022 </p>
</li>
</ul>
<ul>
<li><p><b>Context-Aware Language Modeling for Goal-Oriented Dialogue Systems</b>
<br /> Charlie Snell, Sherry Yang, Justin Fu, Yi Su, Sergey Levine
<br /> <a href="https://arxiv.org/pdf/2204.10198.pdf">[PDF]</a>  Proceedings of NAACL, 2022 </p>
</li>
</ul>
 <ul>
<li><p><b>Offline RL for Natural Language Generation with Implicit Language Q Learning</b>
<br /> Charlie Snell, Ilya Kostrikov, Yi Su, Mengjiao Yang, Sergey Levine
<br /> <a href="https://arxiv.org/pdf/2206.11871.pdf">[PDF]</a>  ArXiv Preprint, 2022 </p>
</li>
</ul>
<ul>
<li><p><b>Online Adaptation to Label Distribution Shift</b>
<br /> Ruihan Wu, Chuan Guo, Yi Su, Kilian Q Weinberger
<br /> <a href="https://arxiv.org/pdf/2107.04520.pdf">[PDF]</a>   Neural Information Processing Systems (NeurIPS), 2021 </p>
</li>
</ul>
<ul>
<li><p><b>Recommendations as Treatments</b>
<br /> Thorsten Joachims, Ben London, Yi Su, Adith Swaminathan, Lequn Wang
<br /> A.I.Magazine, 2021 </p>
</li>
</ul>
<ul>
<li><p><b>Doubly robust off-policy evaluation with shrinkage</b>
<br /> Yi Su, Maria Dimakopoulou, Akshay Krishnamurthy, Miroslav Dudik
<br /> <a href="https://arxiv.org/pdf/1907.09623.pdf">[PDF]</a>  International Conference on Machine Learning (ICML), 2020</p>
</li>
</ul>
<ul>
<li><p><b>Adaptive estimator selection for off-policy evaluation</b>
<br /> Yi Su, Pavithra Srinath, Akshay Krishnamurthy
<br /> <a href="https://arxiv.org/pdf/2002.07729.pdf">[PDF]</a> International Conference on Machine Learning (ICML), 2020 </p>
</li>
</ul>
<ul>
<li><p><b>Off-policy Bandits with Deficient Support</b>
<br /> Noveen Sachdeva*, Yi Su*, Thorsten Joachims
<br /> <a href="https://dl.acm.org/doi/pdf/10.1145/3394486.3403139">[PDF]</a> ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2020</p>
</li>
</ul>
<ul>
<li><p><b>CAB: Continuous Adaptive Blending for Policy Evaluation and Learning</b>
<br /> Yi Su*, Lequn Wang*, Michele Santacatterina, Thorsten Joachims
<br /> <a href="https://arxiv.org/pdf/1811.02672.pdf">[PDF]</a> International Conference on Machine Learning (ICML), 2019</p>
</li>
</ul>
<ul>
<li><p><b>Learning from Logged Bandit Feedback of Multiple Loggers</b>
<br /> Yi Su, Aman Agarwal, Thorsten Joachims
<br /> <a href="https://www.cs.cornell.edu/people/tj/publications/su_etal_18a.pdf">[PDF]</a> CausalML Workshop at the International Conference on Machine Learning (CausalML), 2018</p>
</li>
</ul>
<h2>Talks</h2>
<ul>
<li><p><b>Off-policy Evaluation and Learning for Interactive Systems</b>
<br /> Invited talk at SIGIR&rsquo;21 Workshop on Causality Search and Recommendation, June 2021.
<br /> Invited talk at SIGIR&rsquo;21 Workshop on Deep Reinforcement Learning for Information Retrieval, June 2021. </p>
</li>
</ul>
<ul>
<li><p><b>Adaptive Estimator Selection for Off-policy Evaluation</b>
<br /> Netflix Research Seminar, June 2021.
<br /> RL Theory Virtual Seminar, March 2021.</p>
</li>
</ul>
<ul>
<li><p><b>Off-policy Bandits with Deficient Support</b>
<br /> Bloomberg AI, August 2020.</p>
</li>
</ul>
<h2>Service</h2>
<h3>Conference Reviewing</h3>
<ul>
<li><p>International Conference on Machine Learning (ICML), 2019, 2020 (top reviewer), 2021 (expert reviewer), 2022</p>
</li>
<li><p>Neural Information Processing Systems (NeurIPS), 2019, 2020, 2021, 2022</p>
</li>
<li><p>Conference on Artiﬁcial Intelligence (AAAI), 2020, 2021, 2022</p>
</li>
<li><p>International Conference on Learning Representations (ICLR), 2021, 2022</p>
</li>
<li><p>International Conference on Artificial Intelligence and Statistics (AISTATS), 2022</p>
</li>
<li><p>NeurIPS Workshop: Oﬄine Reinforcement Learning, 2020</p>
</li>
</ul>
<h3>Program Committee</h3>
<ul>
<li><p>ICML Workshop: Theoretical Foundations of Reinforcement Learning, 2020</p>
</li>
<li><p>ICML Workshop: Reinforcement Learning Theory, 2021</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2021-08-17 22:09:03 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>
</body>
</html>
